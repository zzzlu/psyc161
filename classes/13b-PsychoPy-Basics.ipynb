{
 "metadata": {
  "name": "",
  "signature": "sha256:e440cddb5b8d0c838e1a30647310412ab1cf3234a80bdf83d9fa6ee7e56233f9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hands-on: PsychoPy -- Stimuli delivery"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Why PsychoPy?\n",
      "\n",
      "- Free and Open-Source\n",
      "- It is in Python: you can enhance your experiment/analysis with anything possible in Python\n",
      "- Cross-platform (although some platforms/releases might get quircky)\n",
      "- Comes with\n",
      "  - GUI Builder (not covered in the class) -- easy to craft an experiment from ground 0\n",
      "  - Coder -- develop/fix experimental scripts.  Very convenient to explore available Demos.  You can as well develop in PyCharm, Spyder or any other Python IDE\n",
      "  - Monitor Center (Tools -> Monitor Center) -- calibrate units (degrees, etc) and colors/lighting for your monitors\n",
      "\n",
      "**DISCLAIMER/WARNING:  do not run your experiments within VirtualBox.  We will keep using class's VirtualBox just for learning PsychoPy.  For real experiments -- install it natively on your laptop/desktop -- it is available across all platforms**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting acquinted"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- start `psychopy` from the terminal (also available in Applications Menu -> NeuroDebian -> Psychophysics -> PsychoPy)\n",
      "- following initial greeting/run\n",
      "- glance over and close Builder window\n",
      "- explore Coder interface\n",
      "- explore/run some demos\n",
      "  - if demo fails to run because needs to save some data to files, \"Save As\" the script under your HOME, and run again\n",
      "- \"calibrate\" your `testMonitor` in \"Monitor Center\""
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic stimuli"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from psychopy import visual, core, event"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inspect options which `Window` provides you with.  Note `winType`, `fullscr`, `monitor`, `units`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visual.Window?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "win = visual.Window(units='deg', monitor='testMonitor')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stim = visual.GratingStim(win, pos=(0., 0.), units='degFlat')\n",
      "stim.draw()\n",
      "win.flip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "win.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Units"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://www.psychopy.org/general/units\n",
      "\n",
      "For conducting demos, the two normalised units (**norm** and **height**) are often handy because the stimulus scales naturally with the window size. \n",
      "\n",
      "For running an experiment it\u2019s usually best to use something like **cm** or **deg** so that the stimulus is a fixed size irrespective of the monitor/window."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **norm**: window ranges in both x and y from -1 to +1\n",
      "* **height**: \n",
      "  - y from -0.5 to 0.5\n",
      "  - x -- depending on aspect ratio (e.g.  -0.6667 to +0.6667 for 4:3 aspect)\n",
      "* **cm**, **deg**: center is at 0"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Colors\n",
      "\n",
      "http://www.psychopy.org/general/colours.html\n",
      "\n",
      "### RGB\n",
      "\n",
      "-        [1,1,1] is white\n",
      "-        [0,0,0] is grey\n",
      "-        [-1,-1,-1] is black\n",
      "-        [1.0,-1,-1] is red\n",
      "-        [1.0,0.6,0.6] is pink\n",
      "\n",
      "Let's explore -- create a window:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "win = visual.Window(units='deg', monitor='testMonitor')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stim = visual.GratingStim(win, color=[1,-1,-1], colorSpace='rgb') #will be red\n",
      "stim.setColor('Firebrick') # one of the web/X11 color names\n",
      "#stim.setColor('#FFFAF0') # an off-white\n",
      "#stim.setColor([0,90,1], colorSpace='dkl') # modulate along S-cone axis in isoluminant plane\n",
      "#stim.setColor([1,0,0], colorSpace='lms')  # modulate only on the L cone\n",
      "#stim.setColor([1,1,1], colorSpace='rgb')  # all guns to max\n",
      "#stim.setColor([1,0,0]) # this is ambiguous - you need to specify a color space\n",
      "stim.draw(); win.flip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clone the window after you are done\n",
      "win.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Basic primitives\n",
      "### TextStim\n",
      "Let's draw a simple text stimuli and wait for subject input:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "win = visual.Window(monitor='testMonitor')\n",
      "stim_text = visual.TextStim(win, text='Welcome', color='black')\n",
      "stim_text.draw()\n",
      "win.flip()\n",
      "event.waitKeys()\n",
      "win.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Excercise**\n",
      "\n",
      "- change the height and orientation of the TextStim\n",
      "- event.waitKeys() waits infinitely. Make it wait for a maximum of 5 seconds and only react to the keys ['space', 'n', 'm']\n",
      "- change background color of the Window to black (text in white)\n",
      "- make window change background black to gray (`win.color`) upon first keypress while still rendering the text and wait for the 2nd keypress.  You would need two `win.flip`s for background color change to take an effect"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### ImageStim"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "win = visual.Window(monitor='testMonitor')\n",
      "stim_image = visual.ImageStim(win, image='imgs/GitHub-PR-demo1.png')\n",
      "stim_text = visual.TextStim(win, text='Welcome')\n",
      "stim_image.size *= [1, -1] # flip vertically\n",
      "print stim_image.size # the size of the stimulus in current units\n",
      "stim_text.pos = [0, 0.6]\n",
      "stim_image.draw()\n",
      "stim_text.draw()\n",
      "win.flip()\n",
      "event.waitKeys()\n",
      "win.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Excercise**\n",
      "- Set image to size of 10 degree visual angle (horizontally)\n",
      "- Make \"Welcome text\" actually visible on top of the image"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Excercise**\n",
      "\n",
      "Let's learn about GratingStim:\n",
      "- make a GratingStim (call it e.g. stim_grating) and show it to see what it does (well, we did it already at the beginning ;) )\n",
      "- change various parameters after it is initiated,\n",
      "  e.g. make a gabor patch by setting mask to a gaussian and spatial\n",
      "  frequency (sf) to 10.\n",
      "- show it on top of stim_image and stim_text with reduced opacity\n",
      "  *hint*: to draw on top, simply draw last.\n",
      "- *Extra credit*: try animating stuff by wrapping draw(), flip() and a change of\n",
      "stimulus attributes in a loop, and break out on a keypress\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Timing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**DISCLAIMER/WARNING:  do not run your experiments within VirtualBox.  We will keep using class's VirtualBox just for learning PsychoPy.  For real experiments -- install it natively on your laptop/desktop -- it is available across all platforms**\n",
      "\n",
      "**DO NOT IGNORE ERROR MESSAGES ABOUT TIMING YOUR SOFTWARE THROWS INTO YOUR FACE**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PsychoPy \u2018blocks\u2019 on the vertical blank interval meaning that, once Window.flip() has been called, no code will be executed until that flip actually takes place. The timestamp for the above frame interval measurements is taken immediately after the flip occurs. \n",
      "\n",
      "Let's use available example script, open in menu of the Coder --> demos --> timing --> timesByFrames.py and run it (press CTRL-R or the green man). It should \n",
      "\n",
      "- show a distribution around 16.667 ms (assuming you're running monitor with 60 Hz) with a narrow distribution (should be within 1ms)\n",
      "- no dropped frames\n",
      "\n",
      "If this doesn't work, you might need to update graphics card drivers.\n",
      "\n",
      "- **Remember** -- under virtualbox our timing could be completely off\n",
      "\n",
      "- **Keep in mind** -- some drivers do not \"block\" for the refresh cycle, thus rendering them somewhat \"undesired\" for running psychophysic experiments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import YouTubeVideo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "YouTubeVideo(\"wts8f1bNnbo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Refresh cycles of LCD/CRT/LCD: https://vimeo.com/24216910"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Recommendations\n",
      "\n",
      "- verify that you have a good card/driver with direct rendering and OpenGL >= 2\n",
      "```\n",
      "> sudo apt-get install mesa-utils\n",
      "> glxinfo | grep -e \"OpenGL version\" -e 'direct rendering'\n",
      "direct rendering: Yes\n",
      "OpenGL version string: 3.0 Mesa 10.4.2\n",
      "```\n",
      "- shut down as many programs, including background processes (anti-virus, email checking, backup, etc). And better disconnect from internet altogether\n",
      "- disable any desktop special effects\n",
      "- run in full-screen mode\n",
      "- generate your stimuli in advance, then just adjust their properties and use (.draw) whenever necessary\n",
      "- avoid heavy computation (as well as native Python loops) within your trials.  Optimize for speed -- use numpy arrays, numexpr, etc in cases where computation is necessary\n",
      "\n",
      "\n",
      "More:\n",
      "- http://www.psychopy.org/general/timing/reducingFrameDrops.html\n",
      "- http://osdoc.cogsci.nl/miscellaneous/timing/#understanding-your-monitor\n",
      "- http://docs.expyriment.org/Timing.html#visual"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Hint (if not obvious)**\n",
      "\n",
      "In your code get timing (`clock.getTime()`) or send triggers (`port.setData(5)`) only after `win.flip()` call!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "In God We Trust, but let's verify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Excercise**\n",
      "\n",
      "Use `core.Clock` (and its `.reset` and `.getTime`), `win.flip` get estimate of the refresh rate of the monitor.  How: loop for e.g. 100 times, collect stats on how long it took from the previous `flip`.  Report min, max, mean, stddev of the timings.  If you really trust noone, use `time` module to double check ;)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Trial durations and logging of dropped frames"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to make PsychoPy issue warnings whenever a frame slips by.  Let's setup an example where we would try to reuse pre-generated stimuli while just adjusting their position. And enabling logging of the lost frames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from http://www.psychopy.org/general/timing/detectingFrameDrops.html#turn-on-frame-time-recording\n",
      "from psychopy import visual, logging, core\n",
      "win = visual.Window([800,600], monitor='testDisplay')\n",
      "win.setRecordFrameIntervals(True)\n",
      "win._refreshThreshold = 1/60.0 + 0.004 #i've got 60Hz monitor and want to allow 4ms tolerance\n",
      "# set the log module to report warnings to the std output window (default is errors only)\n",
      "logging.console.setLevel(logging.WARNING)\n",
      "\n",
      "clock = core.Clock()\n",
      "stim_texts = [visual.TextStim(win, t) for t in ('Hello world', 'Bye bye world')]\n",
      "clock.reset() # so we could get timing whenever we are done\n",
      "for frame in xrange(20):\n",
      "    # Use a pregenerated stimuli changing from one to another on each \"frame\"\n",
      "    # TODO\n",
      "    stim_text = # TODO\n",
      "    # Just adjust its properties, .e.g text.pos, to go diagonally\n",
      "    stim_text.pos = \n",
      "    # wait for almost 20 frames\n",
      "    core.wait(19.9*1./60)\n",
      "win.flip() # clear it out for the final one\n",
      "dt = clock.getTime()\n",
      "print \"We should have got 1(initial flip)+20*20+1 flips, which should have taken at 60Hz %.3fms. \"\\\n",
      "      \"dt was %.3fms\" %((1+20*20+1)/60., dt)\n",
      "# whenever done\n",
      "win.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "comment out interesting to you specifications, run next cell repetitevely with different values to see effect"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}